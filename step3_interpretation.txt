INTERPRETATION GUIDE: Step 3 - Machine Learning Classification
================================================================

This guide helps you understand what the results from step3_machine_learning.ipynb mean.

WHAT THIS NOTEBOOK DOES:
------------------------
This notebook trains machine learning models to predict Demented vs Nondemented using the extracted brain features.

KEY OUTPUTS TO UNDERSTAND:
--------------------------

1. Accuracy Scores
   - Training Accuracy: How well model fits training data
   - Testing Accuracy: How well model generalizes to new data (MOST IMPORTANT)
   - What's good? For medical diagnosis, >70% is acceptable, >80% is good
   - Warning: If training accuracy >> testing accuracy = overfitting (model memorized data)

2. Confusion Matrix (confusion_matrices.png)
   - True Negatives (TN): Correctly predicted Nondemented (top-left)
   - False Positives (FP): Predicted Demented but actually Nondemented (top-right)
   - False Negatives (FN): Predicted Nondemented but actually Demented (bottom-left)
   - True Positives (TP): Correctly predicted Demented (bottom-right)
   - What to look for: More values on diagonal (TN and TP) = better model
   - Medical context: False Negatives are worse (missing a dementia case)

3. Classification Report
   - Precision: Of all predictions for a class, how many were correct?
     * High precision = fewer false positives
   - Recall: Of all actual cases, how many did we catch?
     * High recall = fewer false negatives
   - F1-Score: Balance between precision and recall
   - For medical diagnosis: Recall is often more important (we want to catch all cases)

4. ROC Curve & AUC (roc_curves.png)
   - ROC Curve: Trade-off between True Positive Rate and False Positive Rate
   - AUC (Area Under Curve):
     * AUC = 0.5: Random guessing (bad)
     * AUC = 0.7-0.8: Acceptable
     * AUC = 0.8-0.9: Good
     * AUC > 0.9: Excellent
   - Higher AUC = better at distinguishing between classes
   - If AUC < 0.7, the model isn't very useful

5. Feature Importance (feature_importance.png)
   - Shows which brain characteristics the model uses most
   - Higher importance = that feature contributes more to predictions
   - Interpretation: High-importance features are likely biomarkers for dementia
   - Can help identify which brain regions/characteristics matter most

6. Cross-Validation Results (cv_results.png)
   - More reliable than single train/test split
   - Shows consistency across multiple data splits
   - Lower standard deviation = more stable/trustworthy model
   - Mean accuracy across all folds = best estimate of true performance

MODEL COMPARISON:
-----------------
- Logistic Regression: Simple, interpretable, good baseline
- Random Forest: More complex, usually better performance, can capture non-linear patterns
- Typically: Random Forest > Logistic Regression for this type of data

WHAT GOOD RESULTS LOOK LIKE:
----------------------------
- Testing accuracy > 70% (ideally > 80%)
- AUC > 0.75 (ideally > 0.85)
- Confusion matrix: Most values on diagonal
- Cross-validation: Low standard deviation (< 0.05)
- Feature importance: Some features clearly more important than others

COMMON QUESTIONS:
-----------------
Q: Why is testing accuracy lower than training accuracy?
A: This is normal! The model hasn't seen test data before. Small difference (<10%) is good.

Q: What if accuracy is very low (<60%)?
A: The features might not be discriminative enough, or you need more data. Try CNNs in Step 4.

Q: Which model should I use?
A: Use the one with higher testing accuracy and AUC. Usually Random Forest.

Q: Can I trust these results with only 75 subjects?
A: Results are preliminary. More data would give more reliable estimates. Cross-validation helps.

Q: What do the saved .pkl files do?
A: They let you use the trained models later without retraining. The scaler is needed to preprocess new data.

NEXT STEPS:
-----------
After running this notebook, you should have:
- Trained models saved as .pkl files
- Performance metrics and visualizations
- Understanding of model strengths/weaknesses
- Ready to move to Step 4 (CNNs) for potentially better performance

